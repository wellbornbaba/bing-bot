# Generated by Selenium IDE
import sys
from os import path
from time import sleep
import requests
import json
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support import expected_conditions
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup as bs
import random


def respath(paths):
    try:
        base_path = sys._MEIPASS
    except Exception:
        base_path = ''

    return path.join(base_path, paths)
    

def remoteread(dfile, agent='', proxy=''):
    try:
        with requests.get(dfile, headers={'User-Agent': agent},
                          verify=False, stream=True, proxies={"http": proxy, "https": proxy}) as response:
            allowcode = [200, 202, 201, 203, 206, 302, 301, 303, 305, 307, 404]
            if response.status_code in allowcode:
                # now proceed with the grabbing
                return response.content
                #return response.content.decode('utf-8')
            else:
                return response.status_code
    except Exception as e:
        print('Requests ' + str(e))
        return False


def getLinks(contents):
  linkresult = []
  
  htmlcontent = bs(contents, 'html.parser')

  try:
    resultdiv = htmlcontent.find('ol', id="b_results")

    # get the content
    for hrefr in resultdiv.find_all('li', class_='b_algo'):
      linkresult.append(hrefr.find('a')['href'])
      
  except Exception as e:
    print('Bing Link Parseing error:', e)
      
  return linkresult
        
        
def bing(words, appLaunchDir, nextpage='', agent='', useip=''):
    allcontent = []
    appLaunchDir = respath(appLaunchDir)
    pathdrive = ChromeDriverManager(path=appLaunchDir).install()
    try:
        option = Options()
        option.add_argument('--ignore-certificate-errors')
        #option.add_argument("--test-type")
        #option.add_argument("--headless")
        option.add_argument("--disable-extensions")
        option.add_argument("--no-sandbox")
        option.add_argument("--start-maximized")
        option.add_argument("--enable-automation")
        option.add_argument("--disable-notifications")
        #option.add_argument("--disable-xss-auditor")
        option.add_argument("--disable-web-security")
        option.add_argument("--no-default-browser-check")
        option.add_argument("--no-first-run")
        #option.add_argument("--window-size=1920,1080")
        if agent:
          option.add_argument(f"--user-agent={agent}")
        if useip: 
            option.add_argument(f"--proxy-server={useip}")
        waitfor = 'sb_form_q'
        browser = webdriver.Chrome(executable_path=pathdrive, options=option)
        #try parsing with selenium
        browser.get("https://www.bing.com/")
        #wait for the browser page to load
        waitToLoad = WebDriverWait(browser, 5)
        #wait until the target class is loaded and found
        waitToLoad.until(EC.presence_of_element_located((By.ID, waitfor)))
        # 3 | click | id=sb_form_q | 
        browser.find_element(By.ID, waitfor).click()
        # 4 | type | id=sb_form_q | doctors
        browser.find_element(By.ID, waitfor).send_keys(words)
        sleep(4)
        # 5 | click | css=.search > svg | 
        browser.find_element(By.CSS_SELECTOR, ".search > svg").click()
        # 6 | runScript | window.scrollTo(0,1619) | 
        browser.execute_script("window.scrollTo(0,119)")
        sleep(3)
        # 7 | runScript | window.scrollTo(0,2126) | 
        browser.execute_script("window.scrollTo(0,2126)")
        htmlresult = browser.page_source
        allcontent = allcontent + getLinks(htmlresult)
        sleep(5)
        
        if nextpage: 
          countit = 1
          while countit < nextpage:
            countit += 1
            scrollcount = 1
            
            browser.find_element(By.LINK_TEXT, f"{countit}").click()
            
            while True:
              if scrollcount == 2: break
              g = random.randrange(100, 2126)
              browser.execute_script(f"window.scrollTo(0,{g})")
              scrollcount +=1
              sleep(4)
              
            # scroll to the end
            browser.execute_script("window.scrollTo(0,2126)")
            htmlresult = browser.page_source
            allcontent = allcontent + getLinks(htmlresult)
            sleep(5)
        
        browser.quit()
        
    except Exception:
        countit = 1
        manualnext = 10
        url = f'https://www.bing.com/search?q="{words}"'
        
        #try process with get
        try:
          resultcontent = remoteread(url, agent, useip)
          allcontent = allcontent + getLinks(resultcontent)
          while countit < nextpage:
            countplus = manualnext + 1
            
            resultcontent = remoteread(url + f"&first={countplus}", agent, useip)
            allcontent = allcontent + getLinks(resultcontent)
            manualnext += 10
            countit += 1
            
        except Exception as e:
          print('Error occurred ', e)

    return allcontent

'''
# return all fund link in array
hy = bing('yellow pages', r'C:\\ProgramData', 3)
print('\n\n',hy,'\n\n')
'''